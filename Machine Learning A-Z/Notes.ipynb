{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "df0d13c6e358d013"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Linear Regression\n",
    "\n",
    "Linear regression is a foundational concept in machine learning and statistics used to model the relationship between two variables: an **independent variable** (input or feature) and a **dependent variable** (output or target). It assumes that the relationship between these variables is linear, meaning it can be represented as a straight line in a graph.\n",
    "\n",
    "## Key Components of Linear Regression\n",
    "1. **Independent Variable (X)**:\n",
    "   - This is the input or feature used to predict the outcome.\n",
    "   - Example: Hours of study.\n",
    "\n",
    "2. **Dependent Variable (Y)**:\n",
    "   - This is the output or target that you want to predict.\n",
    "   - Example: Test score.\n",
    "\n",
    "3. **Linear Equation**:\n",
    "   - The relationship is expressed as:\n",
    "     \\[\n",
    "     Y = mX + b\n",
    "     \\]\n",
    "     where:\n",
    "     - \\( m \\) (slope): Determines the steepness and direction of the line.\n",
    "     - \\( b \\) (intercept): The value of \\( Y \\) when \\( X = 0 \\).\n",
    "\n",
    "4. **Prediction**:\n",
    "   - Given a value of \\( X \\), the model predicts \\( Y \\) based on the linear equation.\n",
    "\n",
    "## Types of Linear Regression\n",
    "1. **Simple Linear Regression**:\n",
    "   - Involves one independent variable.\n",
    "   - Example: Predicting house prices based on size.\n",
    "\n",
    "2. **Multiple Linear Regression**:\n",
    "   - Involves multiple independent variables.\n",
    "   - Example: Predicting house prices based on size, location, and age.\n",
    "\n",
    "## How It Works\n",
    "1. **Model Training**:\n",
    "   - Linear regression uses a dataset to learn the best values of \\( m \\) (slope) and \\( b \\) (intercept) that minimize the prediction error.\n",
    "   - The error is typically measured using a metric called the **Mean Squared Error (MSE)**, which calculates the average squared difference between predicted and actual values.\n",
    "\n",
    "2. **Optimization**:\n",
    "   - Techniques like **Gradient Descent** are used to find the optimal values of \\( m \\) and \\( b \\) by minimizing the error.\n",
    "\n",
    "3. **Prediction**:\n",
    "   - Once trained, the model can predict \\( Y \\) for new values of \\( X \\) using the learned equation.\n",
    "\n",
    "## Example of Simple Linear Regression\n",
    "Let’s say you want to predict the test score based on hours of study.\n",
    "\n",
    "| Hours of Study (X) | Test Score (Y) |\n",
    "|---------------------|---------------|\n",
    "| 1                   | 50            |\n",
    "| 2                   | 55            |\n",
    "| 3                   | 60            |\n",
    "| 4                   | 65            |\n",
    "| 5                   | 70            |\n",
    "\n",
    "A linear regression model would find the line that best fits this data. It might calculate:\n",
    "\\[\n",
    "Y = 5X + 45\n",
    "\\]\n",
    "If you study for 6 hours, the model predicts:\n",
    "\\[\n",
    "Y = 5(6) + 45 = 75\n",
    "\\]\n",
    "\n",
    "## Advantages of Linear Regression\n",
    "1. Simple and easy to implement.\n",
    "2. Works well for problems with a linear relationship between variables.\n",
    "3. Interpretable—provides insights into how input variables affect the output.\n",
    "\n",
    "## Limitations\n",
    "1. Assumes the relationship between variables is linear.\n",
    "2. Sensitive to outliers, which can distort the results.\n",
    "3. Struggles with complex relationships (non-linear data).\n",
    "\n"
   ],
   "id": "c990408e6756c053"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "736f41d82405a891"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Feature Scaling\n",
    "\n",
    "Feature scaling is a preprocessing technique in machine learning where the range of independent variables (features) is adjusted to ensure that all features contribute equally to the model. Many machine learning algorithms (e.g., gradient descent, k-means clustering) perform better when input features are scaled to a similar range.\n",
    "\n",
    "## Why is Feature Scaling Important?\n",
    "1. **Avoid Bias Toward Larger Features**:\n",
    "   - Algorithms like linear regression or neural networks calculate weights based on feature values. Larger values can dominate smaller ones if features are not scaled.\n",
    "\n",
    "2. **Speed Up Training**:\n",
    "   - Gradient-based optimizers converge faster when features are scaled.\n",
    "\n",
    "3. **Improve Model Performance**:\n",
    "   - Algorithms like Support Vector Machines (SVM) and k-Nearest Neighbors (k-NN) are sensitive to the scale of input data.\n",
    "\n",
    "---\n",
    "\n",
    "# Standardization\n",
    "\n",
    "**Standardization** is a feature scaling technique that transforms the data to have a mean of 0 and a standard deviation of 1. It assumes the data follows a Gaussian (normal) distribution, but it can work even if the data is not perfectly normal.\n",
    "\n",
    "### Formula for Standardization\n",
    "\\[\n",
    "Z = \\frac{X - \\mu}{\\sigma}\n",
    "\\]\n",
    "where:\n",
    "- \\( Z \\): Standardized value\n",
    "- \\( X \\): Original value\n",
    "- \\( \\mu \\): Mean of the feature\n",
    "- \\( \\sigma \\): Standard deviation of the feature\n",
    "\n",
    "### Benefits of Standardization\n",
    "1. Makes the feature distribution **centered** (mean = 0) and **scaled** (variance = 1).\n",
    "2. Useful for algorithms like:\n",
    "   - Logistic regression\n",
    "   - SVMs\n",
    "   - Principal Component Analysis (PCA)\n",
    "\n",
    "---\n",
    "\n",
    "# Median\n",
    "\n",
    "The **median** is a statistical measure that represents the middle value of a dataset when it is ordered. It divides the data into two equal halves:\n",
    "- Half the values are smaller than the median.\n",
    "- Half the values are larger.\n",
    "\n",
    "### How to Calculate the Median\n",
    "1. **Sort the data** in ascending order.\n",
    "2. Find the middle value:\n",
    "   - If the dataset size \\( n \\) is odd, the median is the middle value.\n",
    "   - If \\( n \\) is even, the median is the average of the two middle values.\n",
    "\n",
    "#### Example:\n",
    "**Dataset**: [1, 3, 7, 9, 11]\n",
    "- \\( n = 5 \\) (odd), Median = \\( 7 \\) (3rd value)\n",
    "\n",
    "**Dataset**: [1, 3, 7, 9]\n",
    "- \\( n = 4 \\) (even), Median = \\( \\frac{7 + 9}{2} = 8 \\)\n",
    "\n",
    "### Why Use Median?\n",
    "- It is robust to **outliers**. Unlike the mean, the median is not influenced by extreme values in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "# Comparing Mean, Median, and Standardization\n",
    "| Measure         | Description                                                                 |\n",
    "|------------------|-----------------------------------------------------------------------------|\n",
    "| **Mean**         | Average of all values. Sensitive to outliers.                              |\n",
    "| **Median**       | Middle value. Resistant to outliers.                                       |\n",
    "| **Standardization** | Adjusts data to have mean = 0, standard deviation = 1 for uniform scaling. |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like a practical Python example for feature scaling using standardization? Let me know!"
   ],
   "id": "4140b8c010e04e32"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# What is Scikit-Learn?\n",
    "\n",
    "**Scikit-learn (sklearn)** is a powerful, open-source machine learning library in Python. It provides simple and efficient tools for data analysis, preprocessing, and implementing a wide range of machine learning algorithms. Scikit-learn is built on top of foundational Python libraries like **NumPy**, **SciPy**, and **Matplotlib**.\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Features of Scikit-learn**\n",
    "\n",
    "### 1. **Machine Learning Algorithms**\n",
    "- Scikit-learn implements a variety of algorithms for:\n",
    "  - **Supervised Learning** (e.g., regression, classification).\n",
    "  - **Unsupervised Learning** (e.g., clustering, dimensionality reduction).\n",
    "\n",
    "### 2. **Data Preprocessing**\n",
    "- Tools for scaling, normalizing, and encoding data.\n",
    "- Example: Handling missing values or converting categorical data into numerical format.\n",
    "\n",
    "### 3. **Model Selection**\n",
    "- Functions for splitting datasets into training and testing sets.\n",
    "- Tools for hyperparameter tuning using techniques like cross-validation and grid search.\n",
    "\n",
    "### 4. **Evaluation Metrics**\n",
    "- A wide range of metrics to evaluate the performance of models (e.g., accuracy, precision, recall, F1-score).\n",
    "\n",
    "### 5. **Pipelines**\n",
    "- Enables chaining of data preprocessing and model training into a single workflow.\n",
    "\n",
    "### 6. **Integration**\n",
    "- Works seamlessly with libraries like NumPy (for arrays), Pandas (for DataFrames), and Matplotlib (for visualization).\n",
    "\n",
    "---\n",
    "\n",
    "## **Why Use Scikit-learn?**\n",
    "\n",
    "1. **Ease of Use**:\n",
    "   - Provides a consistent API across all machine learning algorithms.\n",
    "   - Minimal coding required to implement complex tasks.\n",
    "\n",
    "2. **Efficiency**:\n",
    "   - Optimized for performance, leveraging NumPy for fast numerical computations.\n",
    "\n",
    "3. **Comprehensive Documentation**:\n",
    "   - Well-documented with many examples, making it beginner-friendly.\n",
    "\n",
    "4. **Versatility**:\n",
    "   - Covers a wide range of machine learning problems.\n",
    "\n",
    "5. **Community Support**:\n",
    "   - One of the most popular ML libraries, with an active community.\n",
    "\n",
    "---\n",
    "\n",
    "## **Common Applications of Scikit-learn**\n",
    "\n",
    "1. **Regression**:\n",
    "   - Predicting continuous outcomes (e.g., house prices).\n",
    "   - Example: `LinearRegression`, `Ridge`.\n",
    "\n",
    "2. **Classification**:\n",
    "   - Predicting discrete labels (e.g., spam or not spam).\n",
    "   - Example: `LogisticRegression`, `RandomForestClassifier`.\n",
    "\n",
    "3. **Clustering**:\n",
    "   - Grouping similar data points together (e.g., customer segmentation).\n",
    "   - Example: `KMeans`, `DBSCAN`.\n",
    "\n",
    "4. **Dimensionality Reduction**:\n",
    "   - Reducing the number of features in a dataset (e.g., PCA).\n",
    "\n",
    "5. **Model Evaluation**:\n",
    "   - Assessing model performance with metrics like accuracy, precision, recall, and AUC.\n",
    "\n",
    "---\n",
    "\n",
    "## **Example: Using Scikit-learn for Classification**\n",
    "\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the Iris dataset\n",
    "data = load_iris()\n",
    "X = data.data  # Features\n",
    "y = data.target  # Labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model Accuracy: {accuracy:.2f}\")"
   ],
   "id": "130cf08fc0a7f514"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
